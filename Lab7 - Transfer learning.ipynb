{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A-crdTZH56Xk",
    "outputId": "f594e876-b5ea-4782-ebfb-6f6fefe484b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1E6LIfRf3UDcIDCgl8ZBI2j0odmvS5c-w\n",
      "To: /content/kaggle_transfer_learning_covid.zip\n",
      "105MB [00:01, 67.2MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Downloading raw data required for training \n",
    "\n",
    "!gdown https://drive.google.com/uc?id=1E6LIfRf3UDcIDCgl8ZBI2j0odmvS5c-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "omlvk451CVM4"
   },
   "outputs": [],
   "source": [
    "# Unzip the the file on the local instance\n",
    "\n",
    "!unzip -qq kaggle_transfer_learning_covid.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YGdKTl7VYaQV"
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import os\n",
    "import cv2 as cv\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#### YOUR CODE HERE ####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "pNFTvntpYhzf"
   },
   "outputs": [],
   "source": [
    "# Path of the dataset\n",
    "data_path = 'C:/Windows/System32/ML_PATH/Electrothon 3.0/kaggle_transfer_learning_covid - Copy/'\n",
    "train_dir = os.path.join(data_path,'train')\n",
    "test_dir = os.path.join(data_path, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "XFd-Sjmg0grG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.applications import DenseNet201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K4S_Ez16YiC6",
    "outputId": "532cc491-35f0-4dda-ef58-7231fcd6ab32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 262 images belonging to 3 classes.\n",
      "Found 63 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get your train and test data\n",
    "train_datagen=ImageDataGenerator(rotation_range=20,width_shift_range=0.3,height_shift_range=0.3,shear_range=0.2,preprocessing_function=preprocess_input,validation_split=0.2)\n",
    "train_generator=train_datagen.flow_from_directory(train_dir,target_size=(224,224),class_mode='categorical',subset='training',shuffle=True)\n",
    "val_generator=train_datagen.flow_from_directory(train_dir,target_size=(224,224),class_mode='categorical',subset='validation',batch_size=3,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JO2DcxhEYqTI"
   },
   "outputs": [],
   "source": [
    "base_model=DenseNet201(input_shape=[224,224,3],weights='imagenet',include_top=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "XNq0A02IaAKh"
   },
   "outputs": [],
   "source": [
    "x=base_model.output\n",
    "base_model.trainable=False\n",
    "x=keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x=keras.layers.Dense(512,activation='relu')(x)\n",
    "preds=keras.layers.Dense(3,activation='softmax')(x) \n",
    "model=keras.models.Model(inputs=[base_model.input],outputs=[preds]) #specify the inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5NJpwcHW6ZMw"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(lr=0.001),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7W71Xi0zYqWV",
    "outputId": "8b5a2020-fabf-4252-89fb-2364ebad3b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 55s 7s/step - loss: 1.1054 - accuracy: 0.4870 - val_loss: 1.0286 - val_accuracy: 0.5556\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 50s 6s/step - loss: 0.7795 - accuracy: 0.7261 - val_loss: 1.1555 - val_accuracy: 0.5714\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.5603 - accuracy: 0.7913 - val_loss: 1.1085 - val_accuracy: 0.5397\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.4113 - accuracy: 0.8870 - val_loss: 1.2027 - val_accuracy: 0.5714\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.3993 - accuracy: 0.9000 - val_loss: 1.1982 - val_accuracy: 0.5873\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 51s 6s/step - loss: 0.3460 - accuracy: 0.9062 - val_loss: 1.2729 - val_accuracy: 0.5873\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 48s 6s/step - loss: 0.3436 - accuracy: 0.9043 - val_loss: 1.3421 - val_accuracy: 0.5714\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.2779 - accuracy: 0.9261 - val_loss: 1.3860 - val_accuracy: 0.5873\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.2945 - accuracy: 0.9130 - val_loss: 1.4574 - val_accuracy: 0.5873\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 50s 6s/step - loss: 0.2652 - accuracy: 0.9348 - val_loss: 1.4861 - val_accuracy: 0.5873\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b26e40fec8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size_train=train_generator.n//train_generator.batch_size\n",
    "step_size_validation=val_generator.n//val_generator.batch_size \n",
    "\n",
    "model.fit(train_generator,validation_data=val_generator,steps_per_epoch=step_size_train,validation_steps=step_size_validation,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UiiFGZMk5bDC",
    "outputId": "382dd97d-36fa-414c-d3c3-c6dd6c2dbe17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20\n",
      "8/8 [==============================] - 50s 6s/step - loss: 0.2513 - accuracy: 0.9348 - val_loss: 1.5693 - val_accuracy: 0.5714\n",
      "Epoch 12/20\n",
      "8/8 [==============================] - 50s 6s/step - loss: 0.2209 - accuracy: 0.9522 - val_loss: 1.4998 - val_accuracy: 0.5873\n",
      "Epoch 13/20\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.2326 - accuracy: 0.9391 - val_loss: 1.5044 - val_accuracy: 0.5714\n",
      "Epoch 14/20\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.2322 - accuracy: 0.9565 - val_loss: 1.5694 - val_accuracy: 0.5714\n",
      "Epoch 15/20\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.1997 - accuracy: 0.9522 - val_loss: 1.6095 - val_accuracy: 0.5714\n",
      "Epoch 16/20\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.1762 - accuracy: 0.9565 - val_loss: 1.6215 - val_accuracy: 0.5873\n",
      "Epoch 17/20\n",
      "8/8 [==============================] - 53s 7s/step - loss: 0.1973 - accuracy: 0.9609 - val_loss: 1.5141 - val_accuracy: 0.5873\n",
      "Epoch 18/20\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.1946 - accuracy: 0.9565 - val_loss: 1.6980 - val_accuracy: 0.5873\n",
      "Epoch 19/20\n",
      "8/8 [==============================] - 52s 6s/step - loss: 0.1798 - accuracy: 0.9453 - val_loss: 1.7200 - val_accuracy: 0.5873\n",
      "Epoch 20/20\n",
      "8/8 [==============================] - 49s 6s/step - loss: 0.1815 - accuracy: 0.9522 - val_loss: 1.5854 - val_accuracy: 0.5714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b26e551608>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator,validation_data=val_generator,steps_per_epoch=step_size_train,validation_steps=step_size_validation,initial_epoch=10,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "5OKGUvdFYqb2"
   },
   "outputs": [],
   "source": [
    "sub=pd.read_csv('kaggle_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "rinSyVD0Y2CN",
    "outputId": "2c5ebad0-bfb4-4cd9-812b-c506cbe2110c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image1.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image2.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image3.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image4.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image5.jpeg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image  class\n",
       "0  image1.jpeg    NaN\n",
       "1  image2.jpeg    NaN\n",
       "2  image3.jpeg    NaN\n",
       "3  image4.jpeg    NaN\n",
       "4  image5.jpeg    NaN"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "6kuJ-ZPdgsG_"
   },
   "outputs": [],
   "source": [
    "images=list(sub['image'])\n",
    "test_list=[]\n",
    "for image in images:\n",
    "  arr=cv.imread(test_dir+'/'+image)\n",
    "  arr=cv.resize(arr,(224,224),interpolation=cv.INTER_LINEAR)\n",
    "  arr=preprocess_input(arr)\n",
    "  test_list.append(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "B5mBTU_9hjVF"
   },
   "outputs": [],
   "source": [
    "test_arr=np.array(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "lpbyo6OtlVOH"
   },
   "outputs": [],
   "source": [
    "predictions_probab=model.predict(test_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "R80JyKfBmAby"
   },
   "outputs": [],
   "source": [
    "predictions_label=np.argmax(predictions_probab,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4TbgM3mwrv5G",
    "outputId": "2a102724-4e9c-4654-b8d9-0cdba17aa17e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 0, 2, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 2,\n",
       "       2, 1, 2, 2, 2, 2, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 2, 0, 2, 2, 2, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 0, 0, 2])"
      ]
     },
     "execution_count": 106,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "G1RSFuZgr6RV"
   },
   "outputs": [],
   "source": [
    "sub['class']=predictions_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "XN4ROVB7qzp2"
   },
   "outputs": [],
   "source": [
    "def category(x):\n",
    "  if x==0:\n",
    "    return 'covid'\n",
    "  elif x==1:\n",
    "    return 'normal'\n",
    "  else:\n",
    "    return 'pneumonia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "FbsIgwGqoa8M"
   },
   "outputs": [],
   "source": [
    "sub['class']=sub['class'].apply(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "4fGaeYnkqSW3",
    "outputId": "b7e731bc-3051-4aeb-fd4e-0917a297c634"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image1.jpeg</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image2.jpeg</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image3.jpeg</td>\n",
       "      <td>pneumonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image4.jpeg</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image5.jpeg</td>\n",
       "      <td>pneumonia</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image      class\n",
       "0  image1.jpeg      covid\n",
       "1  image2.jpeg     normal\n",
       "2  image3.jpeg  pneumonia\n",
       "3  image4.jpeg      covid\n",
       "4  image5.jpeg  pneumonia"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "ITLZuqJXrYC1"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submissions.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0_7pcSZt7Il"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Scaffold.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "tf2-gpu.2-1.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
